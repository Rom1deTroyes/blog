---
title: "Le NLP : Natural Language Processing"
layout: single
permalink: /nlp/

---


## Qu’est-ce que le NLP ?

Le Natural Language Processing (NLP) ou le Traitement Automatique du Langage Naturel (TALN) en français est un domaine à l’intersection de l’informatique, de l’intelligence artificielle et de la linguistique.
L’objectif de cette discipline est de permettre à des ordinateurs de traiter le langage naturel produits par des humains.
<br><br>


## Quelles sont les applications concrètes du NLP ?

Voici une liste non exhaustive d'exemples d’applications :
- la traduction automatique
- la classification de texte 
- la génération de texte (résumé)
- la génération de réponses à des questions complèxes (chatbox)
- la reconnaissance vocale
<br><br>


## Quelles sont les méthodes employées pour mettre en place ces applications ?
J'ai réalisé une série d'articles dédiée aux modèles statistiques utilisés en NLP.

Dans un premier temps, vous trouverez les articles de présentation des modèles. Ils sont classés dans l’ordre chronologique de leur popularité d’utilisation. 
Dans un second temps, vous trouverez les articles concernant les sujets utiles à connaître en NLP : les tokenizers, les bases de données, etc...

* Le bag-of-word : l’[article de présentation](https://lbourdois.github.io/blog/nlp/Bag-of-word/)
    
* Le word embedding : l’[article de présentation](https://lbourdois.github.io/blog/nlp/word_embedding/)

* Les RNN, les LSTM et ELMo : l’[article de présentation](https://lbourdois.github.io/blog/nlp/RNN-LSTM-GRU-ELMO/)

* Le Seq2seq et le processus d’attention : l’[article de présentation](https://lbourdois.github.io/blog/nlp/Seq2seq-et-attention/)

* Le Transformer : l’[article de présentation](https://lbourdois.github.io/blog/nlp/Transformer/)

* Les architectures issues du Transformer<br>
Il en existe de nombreuses : une liste non exhaustive est disponible dans le dernier article de la série consacrée au NLP : lire [l'article en question](https://lbourdois.github.io/blog/nlp/Les-architectures-transformers/)<br>
Je présente plus en détails les architectures que j’ai eu l’occasion d’utiliser professionnellement.<br>
    * BERT : l’[article de présentation](https://lbourdois.github.io/blog/nlp/BERT/) et le [tutoriel associé](https://github.com/lbourdois/notebooks_blog/blob/master/Tutoriel%20application%20de%20BERT%20via%20DistillBERT.ipynb)<br>
    * le GPT-2 : l’[article de présentation](https://lbourdois.github.io/blog/nlp/GPT2/)<br>
  
* Les articles concernant les sujets utiles à connaître en NLP :
    * Le prétraitement et les tokenizers : l'[article](https://lbourdois.github.io/blog/nlp/Les-tokenizers/)
    * Les tâches et jeux de données test fréquemment utilisés : l'[article](https://lbourdois.github.io/blog/nlp/Taches-et-jeux-de-donnees-en-NLP/)
